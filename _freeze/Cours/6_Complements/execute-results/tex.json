{
  "hash": "550567802a30650951deb3700a662533",
  "result": {
    "markdown": "---\ntitle: \"6 - Compléments\"\n---\n\n\n\n\n### Objectifs de cette séquence\n\n- Présenter quelques compléments sans exercice associé\n\n\n\n# Régresseurs externes et TBATS\n\n## Régresseurs externes classiques\n\nDans certaines méthodes (régression linéaire, ARIMA, etc. mais pas ETS) permettent de rajouter des régresseurs externes qui peuvent aider à l'analyse/prévision\n\n- polynômes sur les dates (e.g. tendance linéaire) (on peut s'aider de `forecast::tslm()`)\n\n. . .\n\n- indicatrices sur la périodicité (avec variable de contraste) :\n\n\t- Sur les jours de la semaine\n\t\n\t- Sur les mois/trimestres\n\n. . .\n\n- Régresseurs JO :\n\n\t- On compte le nombre de lundis, mardis, ... dans le mois et on construit des variables contraste (en faisant des éventuels regroupement)\n\t\n\t- Régresseurs sur les jours fériés (éventuellement regroupés avec dimanches) + éventuels effets graduels (notamment fêtes mobiles)\n\n\n\n### Régresseurs de Fourier\n\nLorsque la périodicité est trop élevée ou lorsqu'il y plusieurs saisonnalités, ajouter des indicatrices peut être trop coûteux.\n\nSolution : ajouter des variables sinusoïdales aux fréquences étudiées !\n\n$$\n\\cos\\left(\\frac{2 k \\pi}{m}\\right)\\quad\n\\sin\\left(\\frac{2 k \\pi}{m}\\right)\n\\quad\n\\text{ avec }0<k<m\n$$\n\nGénéralement $k\\ll m$ lorsque $m$ est grand\n\n. . .\n\n- Pour séries mensuelles : $m=12$\n\n- Pour les séries hebdomadaires $m=365.25/7\\simeq 52$\n\n- Pour les séries journalières $m=365.25$ pour saisonnalité annuelle, $m=365.25/12\\simeq 30$ pour saisonnalité mensuelle.\n\n### TBATS (1)\n\nUne transformation de Box-Cox est utilisée :\n$$\ny_t^{(\\lambda)}=\\begin{cases}\n\\frac{y_t^\\lambda - 1}{\\lambda}&\\text{if }\\lambda\\ne0\\\\\n\\log(y_t)&\\text{if }\\lambda=0\n\\end{cases}\n$$\nEnsuite un modèle avec *Trigonometric seasonality, ARMA errors, Trend and Seasonal components* est calculé : c'est tout ce que l'on a vu dans les précédents cours.\n\nVoir `?forecast::tbats()`\n\n\n### TBATS (2)\n\n$$\n\\begin{cases}\ny_t^{(\\lambda)}=l_{t-1}+\\phi b_{t-1}+\\sum_{i=1}^T s_{t-m_i}^{(i)}+ d_t \\text{ and }d_t\\sim ARMA(p,q)\\\\\nl_{t}=l_{t-1}+\\phi b_{t-1}+\\alpha d_t \\\\\nb_{t} = \\phi b_{t-1} + \\beta d_t\n\\end{cases}\n$$\n$$\n\\begin{cases}\ns_t^{(i)}=\\sum_{j=1}^{k_i}s_{j,t}^{(i)} \\\\\ns_{j,t}^{(i)}=s_{j,t-1}^{(i)}\\cos \\omega_j+s_{j,t-1}^{*(i)}\\sin \\omega_j +\\gamma_1^{(i)}d_t \\\\\ns_{j,t-1}^{*(i)} = s_{j,t-1}^{(i)}\\sin \\omega_j + s_{j,t-1}^{*(i)}\\cos \\omega_j\n+\\gamma_2^{(i)}d_t\n\\end{cases}\n\\text{ and }\\omega_j=\\frac{2\\pi j}{m_i}\n$$\n\nNotation : $TBATS(omega, p,q, phi, <m1,k1>,...,<mJ,kJ>)$ avec\n\n- $omega$ = paramètre de Box-Cox  \n- $(p,q)$ = ARMA(p,q)  \n- $phi$ = paramètre d'amortissement\n- $m1, ..., mJ$ les périodicités et $k1, ..., kJ$ le nombre de termes de fourrier\n\n\n### TBATS (3)\n\n\n::: {.cell hash='6_Complements_cache/beamer/unnamed-chunk-1_4b662df39a565f4fdb4939a27506d46b'}\n\n```{.r .cell-code}\nlibrary(forecast)\ntbats(USAccDeaths)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTBATS(1, {0,0}, -, {<12,5>})\n\nCall: tbats(y = USAccDeaths)\n\nParameters\n  Alpha: 0.5950012\n  Gamma-1 Values: -0.01207202\n  Gamma-2 Values: 0.01159708\n\nSeed States:\n            [,1]\n [1,] 9357.62824\n [2,] -999.76784\n [3,]  279.84741\n [4,] -193.88870\n [5,]  143.51408\n [6,]  -35.59289\n [7,] -279.82036\n [8,] -319.15409\n [9,] -154.24981\n[10,]  -70.33238\n[11,] -256.67889\n\nSigma: 253.3291\nAIC: 1132.915\n```\n:::\n:::\n\n\n\n### Analyse des données haute fréquence\n\nPour les séries à haute fréquence (hebdomadaires, journalières, horaires, etc.)\n\n::: incremental\n- Les effets calendaires peuvent être relativement importants (notamment les jours feriés)\n\n- On peut utiliser des modèles avec des régresseurs externes (e.g. fourrier)\n\n- TBATS\n\n- On peut combiner des modèles STL + ETS ou ARIMA sur série désaisonnalisée\n:::\n\n. . .\n\nVoir https://otexts.com/fpp2/weekly.html et https://otexts.com/fpp3/weekly.html pour des exemples\n\n### Exemples (1)\n\n\\footnotesize\n\n::: {.cell hash='6_Complements_cache/beamer/tbats-arima-plot_c44df31d8ddf60257de6235f1a9950a7'}\n\n```{.r .cell-code}\nlibrary(forecast);library(ggplot2);library(patchwork)\ny <- fpp2::gasoline\nautoplot(y, main = \"Essence\")\n```\n\n::: {.cell-output-display}\n![](6_Complements_files/figure-beamer/tbats-arima-plot-1.pdf)\n:::\n:::\n\n\n### Exemples (2)\n\n\\footnotesize\n\n::: {.cell hash='6_Complements_cache/beamer/tbats-arima-season_4b48ca3a84e5e743d7f0a491ac37f882'}\n\n```{.r .cell-code}\nfrequency(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 52.17857\n```\n:::\n\n```{.r .cell-code}\nggseasonplot(y, polar = TRUE)\n```\n\n::: {.cell-output-display}\n![](6_Complements_files/figure-beamer/tbats-arima-season-1.pdf){width=70%}\n:::\n:::\n\n\n### Exemples (3)\n\n\\footnotesize\n\n::: {.cell hash='6_Complements_cache/beamer/tbats-arima-mod_7f697b880b9c78fea868821b5872ec2f'}\n\n```{.r .cell-code}\n# Saisonnalité annuelle et mensuelle :\ntbats <- tbats(y, seasonal.periods = c(365.25/7, 365.25/12/7))\narima_fourier <- auto.arima(y, seasonal = FALSE, xreg = fourier(y,K=5))\ntbats\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTBATS(1, {0,0}, 0.8, {<4.35,6>, <52.18,1>})\n\nCall: tbats(y = y, seasonal.periods = c(365.25/7, 365.25/12/7))\n\nParameters\n  Alpha: 0.2350472\n  Beta: -0.03474354\n  Damping Parameter: 0.800008\n  Gamma-1 Values: -0.0002755258 6.336552e-05\n  Gamma-2 Values: 5.566591e-05 5.769457e-05\n\nSeed States:\n              [,1]\n [1,]  6.949478933\n [2,]  0.021926676\n [3,] -0.030850684\n [4,]  0.006212825\n [5,] -0.009773578\n [6,]  0.017276525\n [7,] -0.002030499\n [8,] -0.000195277\n [9,]  0.013708507\n[10,]  0.013423966\n[11,]  0.022447689\n[12,]  0.008275455\n[13,]  0.001822740\n[14,]  0.006285954\n[15,] -0.240243182\n[16,]  0.060682302\n\nSigma: 0.2597114\nAIC: 6164.08\n```\n:::\n:::\n\n\n### Exemples (4)\n\n\\footnotesize\n\n::: {.cell hash='6_Complements_cache/beamer/tbats-arima-forecast_110f6878dc5e996b0f0bfd1c168ef6d9'}\n\n```{.r .cell-code}\nautoplot(window(y, start = 2010)) +\n\tautolayer(forecast(tbats, h = 52*2)$mean, series=\"TBATS\")+\n\tautolayer(forecast(arima_fourier, h = 52*2, xreg = fourier(y, K=5, h = 52*2))$mean,\n\t\t\t  series = \"ARIMA + Fourier\")\n```\n\n::: {.cell-output-display}\n![](6_Complements_files/figure-beamer/tbats-arima-forecast-1.pdf)\n:::\n:::\n\n\n### Exemples analyse de $K$ {.allowframebreaks}\n\n\\footnotesize\n\n::: {.cell hash='6_Complements_cache/beamer/arima-fourier_9c4e03000658d456430bf3d339a6348c'}\n::: {.cell-output-display}\n![](6_Complements_files/figure-beamer/arima-fourier-1.pdf)\n:::\n\n\n\n::: {.cell-output-display}\n![](6_Complements_files/figure-beamer/arima-fourier-2.pdf)\n:::\n\n\n\n::: {.cell-output-display}\n![](6_Complements_files/figure-beamer/arima-fourier-3.pdf)\n:::\n\n\n\n::: {.cell-output-display}\n![](6_Complements_files/figure-beamer/arima-fourier-4.pdf)\n:::\n\n\n\n::: {.cell-output-display}\n![](6_Complements_files/figure-beamer/arima-fourier-5.pdf)\n:::\n\n\n\n::: {.cell-output-display}\n![](6_Complements_files/figure-beamer/arima-fourier-6.pdf)\n:::\n\n\n\n::: {.cell-output-display}\n![](6_Complements_files/figure-beamer/arima-fourier-7.pdf)\n:::\n\n\n\n::: {.cell-output-display}\n![](6_Complements_files/figure-beamer/arima-fourier-8.pdf)\n:::\n\n\n\n::: {.cell-output-display}\n![](6_Complements_files/figure-beamer/arima-fourier-9.pdf)\n:::\n\n\n\n::: {.cell-output-display}\n![](6_Complements_files/figure-beamer/arima-fourier-10.pdf)\n:::\n:::\n\n\n\n\n\n# Modèles ECM\n\n### Modèles ECM\n\nLes modèles à correction d'erreur (ECM) permettent de mettre en relation deux variables $x_t, y_t$ non-stationnaires qui partagent la même tendance stochastique. Modèle suivant est utilisé :\n$$\n\\Delta y_t=\\underbrace{\\gamma + \\sum_{i=1}^p\\Delta y_{t-i} + \\sum_{i=1}^p\\Delta x_{t-i}}_{\\text{court terme}} +\n\\alpha\\underbrace{(y_{t-1}-\\beta_0-\\beta_1 x_{t-1})}_{\\text{long terme}} + \\varepsilon_t\n$$\n\n. . .\n\nPeut s'estimer par double MCO : long terme puis court terme sur les résidus. On peut s'aider de `dynlm::dynlm()` ou utiliser le package `ecm`.\n\n. . .\n\nPour que le modèle soit valide il faut que $y_{t-1}-\\beta_0-\\beta_1 x_{t-1}$ soit stationnaire : on peut faire un test de racine unité sur les résidus ou appliquer le test de Johansen (`urca::ca.jo`).\n\n. . .\n\nGénéralement $\\alpha<0$ : s’interprète comme une force de rappel.\n\n\n### Exemple {.allowframebreaks}\n\n\\footnotesize\n\n\n::: {.cell hash='6_Complements_cache/beamer/unnamed-chunk-2_23a48a46540c7c1843fa975c0778abf7'}\n\n```{.r .cell-code}\n# install.packages(\"PepperPrice\")\nlibrary(urca);library(dynlm);library(forecast);library(ggplot2)\ndata(\"PepperPrice\", package = \"AER\")\n# On passe au log pour analyser les différences comme des évolutions\ndata_pepper <- log(PepperPrice)\nautoplot(data_pepper) / autoplot(diff(data_pepper))\n```\n\n::: {.cell-output-display}\n![](6_Complements_files/figure-beamer/unnamed-chunk-2-1.pdf)\n:::\n\n```{.r .cell-code}\n# Séries sont dites I(1) :\n# Elles ne sont pas stationnaires\ntseries::kpss.test(data_pepper[,\"black\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tKPSS Test for Level Stationarity\n\ndata:  data_pepper[, \"black\"]\nKPSS Level = 0.60007, Truncation lag parameter = 5, p-value = 0.02263\n```\n:::\n\n```{.r .cell-code}\ntseries::kpss.test(data_pepper[,\"white\"])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tKPSS Test for Level Stationarity\n\ndata:  data_pepper[, \"white\"]\nKPSS Level = 0.61733, Truncation lag parameter = 5, p-value = 0.02106\n```\n:::\n\n```{.r .cell-code}\n# Mais les séries différenciées le sont \ntseries::kpss.test(diff(data_pepper[,\"black\"], 1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tKPSS Test for Level Stationarity\n\ndata:  diff(data_pepper[, \"black\"], 1)\nKPSS Level = 0.15877, Truncation lag parameter = 5, p-value = 0.1\n```\n:::\n\n```{.r .cell-code}\ntseries::kpss.test(diff(data_pepper[,\"white\"], 1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tKPSS Test for Level Stationarity\n\ndata:  diff(data_pepper[, \"white\"], 1)\nKPSS Level = 0.13062, Truncation lag parameter = 5, p-value = 0.1\n```\n:::\n\n```{.r .cell-code}\n# Le test de Johansen doit se lire de manière croissante avec r\n# r=0 signifie qu'il n'y a pas de relation de co-intégration\n# si on le rejette (test > valeurs critiques), on regarde le test suivant\n# Dans notre cas il n'y a que deux tests car on a que deux variables\n# Le test est plus général pour les cas où l'on fait des VECM\n# (potentiellement plusieurs relations de cointegration)\n# Ici on conclut qu'il y a bien relation de cointegration\nsummary(ca.jo(data_pepper))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n###################### \n# Johansen-Procedure # \n###################### \n\nTest type: maximal eigenvalue statistic (lambda max) , with linear trend \n\nEigenvalues (lambda):\n[1] 0.04923322 0.01262841\n\nValues of teststatistic and critical values of test:\n\n          test 10pct  5pct  1pct\nr <= 1 |  3.42  6.50  8.18 11.65\nr = 0  | 13.58 12.91 14.90 19.19\n\nEigenvectors, normalised to first column:\n(These are the cointegration relations)\n\n           black.l2  white.l2\nblack.l2  1.0000000  1.000000\nwhite.l2 -0.8904272 -6.177004\n\nWeights W:\n(This is the loading matrix)\n\n           black.l2    white.l2\nblack.d -0.07423986 0.001970073\nwhite.d  0.02088163 0.002811481\n```\n:::\n\n```{.r .cell-code}\n# On estime la relation de long-terme\nlm_lt <- lm(black ~ white, data = data_pepper)\nresid_lt <- ts(residuals(lm_lt), start = start(data_pepper), \n\t\t\t  frequency = frequency(data_pepper))\nautoplot(resid_lt)\n```\n\n::: {.cell-output-display}\n![](6_Complements_files/figure-beamer/unnamed-chunk-2-2.pdf)\n:::\n\n```{.r .cell-code}\n# La série est bien stationnaire\ntseries::kpss.test(resid_lt)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tKPSS Test for Level Stationarity\n\ndata:  resid_lt\nKPSS Level = 0.23504, Truncation lag parameter = 5, p-value = 0.1\n```\n:::\n\n```{.r .cell-code}\n# Rmq il y a quelques points atypiques que l'on pourrait corriger\n# en ajoutant par exemple des indicatrices\n# On peut aussi utiliser la fonction forecast::tsoutliers() pour les repérer\n# En reprenant le code disponible ici\n# https://robjhyndman.com/hyndsight/tsoutliers/ :\nautoplot(tsclean(resid_lt), series=\"clean\", color='red', lwd=0.9) +\n\tautolayer(resid_lt, series=\"original\", color='gray', lwd=1) +\n\tgeom_point(data = tsoutliers(resid_lt) %>% as.data.frame(),\n\t\t\t   aes(x=time(resid_lt)[index], y=replacements), col='blue')\n```\n\n::: {.cell-output-display}\n![](6_Complements_files/figure-beamer/unnamed-chunk-2-3.pdf)\n:::\n\n```{.r .cell-code}\ndata <- ts.union(data_pepper, resid_lt)\ncolnames(data) <- c(colnames(data_pepper), \"long_term\")\n# On a bien une force de rappel négative\nsummary(\n\tdynlm(diff(black, 1) ~ lag(diff(black, 1),-1) + \n\t\t  \tlag(diff(white, 1),-1) + \n\t\t  \tlag(long_term, -1), data = data)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nTime series regression with \"ts\" data:\nStart = 1973(12), End = 1996(4)\n\nCall:\ndynlm(formula = diff(black, 1) ~ lag(diff(black, 1), -1) + lag(diff(white, \n    1), -1) + lag(long_term, -1), data = data)\n\nResiduals:\n      Min        1Q    Median        3Q       Max \n-0.200930 -0.035547 -0.005632  0.028757  0.228076 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              0.001830   0.003876   0.472  0.63724    \nlag(diff(black, 1), -1)  0.327341   0.069431   4.715 3.92e-06 ***\nlag(diff(white, 1), -1)  0.051700   0.069819   0.740  0.45966    \nlag(long_term, -1)      -0.072551   0.027006  -2.686  0.00768 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.06345 on 265 degrees of freedom\nMultiple R-squared:  0.144,\tAdjusted R-squared:  0.1343 \nF-statistic: 14.86 on 3 and 265 DF,  p-value: 5.698e-09\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}